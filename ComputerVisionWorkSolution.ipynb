{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMhXsHRzNI+XvNHkMVVbHv4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Save all images of video"
      ],
      "metadata": {
        "id": "uBBXzP2OFfYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "camera = cv2.VideoCapture(\"NewObjectDetector.mp4\")\n",
        "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
        "counter = 0\n",
        "\n",
        "while camera.isOpened():\n",
        "    ret, frame = camera.read()\n",
        "    if ret:\n",
        "\n",
        "        try:\n",
        "            image = cv2.resize(frame, (960, 540))\n",
        "            print(f'Saving Image No. {counter}')\n",
        "            cv2.imwrite(f'Data/{counter}.bmp', image)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "        counter +=1\n",
        "    else:\n",
        "        print('Frame not available')\n",
        "        break\n"
      ],
      "metadata": {
        "id": "zMUfPWxLFhvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access camera with opencv and tkinter"
      ],
      "metadata": {
        "id": "Ts5CSLsVOBiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "from tkinter import *\n",
        "import tkinter.font as font\n",
        "from PIL import Image, ImageTk\n",
        "import cv2\n",
        "\n",
        "# Create an instance of TKinter Window or frame\n",
        "win = Tk()\n",
        "def quit():\n",
        "        win.destroy()\n",
        "\n",
        "# Create a Label to capture the Video frames\n",
        "label =Label(win)\n",
        "label.grid(row=0, column=0)\n",
        "cap= cv2.VideoCapture(0)\n",
        "\n",
        "# Define function to show frame\n",
        "def show_frames():\n",
        "   # Get the latest frame and convert into Image\n",
        "   cv2image= cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB)\n",
        "   img = Image.fromarray(cv2image)\n",
        "   # Convert image to PhotoImage\n",
        "   imgtk = ImageTk.PhotoImage(image = img)\n",
        "   label.imgtk = imgtk\n",
        "   label.configure(image=imgtk)\n",
        "   # Repeat after an interval to capture continiously\n",
        "   label.after(20, show_frames)\n",
        "\n",
        "\n",
        "show_frames()\n",
        "\n",
        "\n",
        "myFont = font.Font(family='Helvetica', size=15)\n",
        "\n",
        "button = Button(win, text = 'Click and Quit',  font=myFont ,command=quit)\n",
        "button.place(relx = 0.4, rely = 0.9, anchor = CENTER)\n",
        "\n",
        "win.mainloop()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "laPGkRGpOCSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save image of certain region and show bound box on realtime camera"
      ],
      "metadata": {
        "id": "_ECC-re3UJAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, Response\n",
        "import base64\n",
        "import cv2\n",
        "from flask import Flask, jsonify, render_template, request\n",
        "import numpy as np\n",
        "import json\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize OpenCV face detection\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Capture video stream from webcam\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "def detect_faces(frame):\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Get the dimensions of the frame\n",
        "    height, width, _ = frame.shape\n",
        "\n",
        "    # Calculate center coordinates\n",
        "    center_x = width // 2\n",
        "    center_y = height // 2\n",
        "\n",
        "    # Set the width and height of the rectangle\n",
        "    rect_width = 250\n",
        "    rect_height = 270\n",
        "\n",
        "    # Calculate the top-left corner coordinates of the rectangle\n",
        "    x = center_x - (rect_width // 2)\n",
        "    y = center_y - (rect_height // 2)\n",
        "    y = y-40\n",
        "\n",
        "\n",
        "    # Define the region of interest (ROI)\n",
        "    roi = frame[y:y+rect_height, x:x+rect_width]\n",
        "    # roi = frame[x:rect_width, y:rect_height]\n",
        "\n",
        "    # Save the cropped image\n",
        "    cv2.imwrite(\"cropped_image.jpg\", roi)\n",
        "    # Draw the rectangle on the frame\n",
        "    cv2.rectangle(frame, (x, y), (x + rect_width, y + rect_height), (0, 255, 0), 2)\n",
        "    return frame\n",
        "\n",
        "\n",
        "def generate_frames():\n",
        "    while True:\n",
        "        # Read frames from the video stream\n",
        "        ret, frame = video_capture.read()\n",
        "\n",
        "        # Process frames (detect faces and draw bounding boxes)\n",
        "        processed_frame = detect_faces(frame)\n",
        "\n",
        "        # Convert processed frame to JPEG format\n",
        "        ret, buffer = cv2.imencode('.jpg', processed_frame)\n",
        "        frame_bytes = buffer.tobytes()\n",
        "\n",
        "        # Yield the frame bytes as an HTTP response\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame_bytes + b'\\r\\n')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')  # Render the HTML page\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the face dictionary from JSON file\n",
        "    with open('face_dict.json', 'r') as json_file:\n",
        "        face_dict = json.load(json_file)\n",
        "    print('Embeddings loaded')\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "_OW4nk_rUrP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Real-time Face Detection</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>Real-time Face Detection</h1>\n",
        "    <img src=\"{{ url_for('video_feed') }}\" width=\"640\" height=\"480\">\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "1LR1nzV0U82N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}